{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ece4ae6-8dbc-4cf8-97b7-ec76c9804427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"id\": \"13f63b43-003f-4a45-870c-6c02f1e62ff5\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Dunder Refresher\"\n",
      "   ]\n",
      "  },\n"
     ]
    }
   ],
   "source": [
    "#  Generator  Example of streaming a file\n",
    "from typing import Iterator,Generator\n",
    "def read_lines()-> Iterator[str]:\n",
    "     with open(\"metaclasses.ipynb\") as fp:\n",
    "         line = fp.readline()\n",
    "         while line:\n",
    "             yield line\n",
    "             line = fp.readline()\n",
    "\n",
    "line_itr = read_lines()\n",
    "i = 0\n",
    "while True:\n",
    "    try:\n",
    "        print(next(line_itr), end='')\n",
    "        i += 1\n",
    "        if i >= 10:\n",
    "            break\n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9890a1c0-ec98-4de8-aeb4-8fd0277497d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16]\n",
      "<class 'generator'>\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mnext\u001b[39m(itr)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mnext\u001b[39m(itr)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print([x*x for x in range(5)])\n",
    "itr = (x*x for x in range(2))\n",
    "print(type(itr))\n",
    "print(isinstance(itr, Iterator))\n",
    "print(isinstance(itr, Generator))\n",
    "next(itr)\n",
    "next(itr)\n",
    "next(itr) # StopIteration                             Traceback (most recent call last)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0808f4c9-73d8-4f02-84a3-1305f653f4c5",
   "metadata": {},
   "source": [
    "Can you write an example of using asyncio in Python to fetch data concurrently from multiple URLs and return the combined results? Include error handling for any failed requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "accb8789-abcc-4622-a002-e5d51b96d168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "### asyncio.gather\n",
      "url_0 started\n",
      "url_1 started\n",
      "url_2 started\n",
      "url_3 started\n",
      "url_4 started\n",
      "url_5 started\n",
      "url_6 started\n",
      "url_7 started\n",
      "url_8 started\n",
      "url_9 started\n",
      "['url_0 1.8', 'url_1 1.0', 'url_2 1.6', 'url_3 1.3', 'url_4 1.2', 'url_5 1.2', 'url_6 1.6', 'url_7 1.7', 'url_8 1.5', 'url_9 1.4']\n",
      "==========\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "*** task url_10 create start\n",
      "___ task url_10 create end\n",
      "### asyncio.gather\n",
      "<_GatheringFuture pending>\n",
      "url_0 started\n",
      "url_1 started\n",
      "url_2 started\n",
      "url_3 started\n",
      "url_4 started\n",
      "url_5 started\n",
      "url_6 started\n",
      "url_7 started\n",
      "url_8 started\n",
      "url_9 started\n"
     ]
    }
   ],
   "source": [
    "# mock http_request\n",
    "import time\n",
    "import asyncio\n",
    "import random\n",
    "async def http_request(url,params={}):\n",
    "    print(f\"{url} started\")\n",
    "    ts = time.time()\n",
    "    sleep_time = 1+random.randrange(0,10)/10\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    return f\"{url} {sleep_time}\"\n",
    "\n",
    "# asyncio.run(http_request(\"my_url\")) : as an event loop is already running on jupyter\n",
    "\n",
    "\n",
    "async def get_data():\n",
    "    urls = [ f\"url_{i}\" for i in range(10)]\n",
    "    tasks = []\n",
    "    for url in urls:\n",
    "        print(f\"*** task url_{i} create start\")\n",
    "        tasks.append(http_request(url))\n",
    "        print(f\"___ task url_{i} create end\")\n",
    "    # asyncio gather \n",
    "    print(\"### asyncio.gather\")  \n",
    "    result = await asyncio.gather(*tasks)\n",
    "    return result\n",
    "\n",
    "async def get_data_no_await():\n",
    "    urls = [ f\"url_{i}\" for i in range(10)]\n",
    "    tasks = []\n",
    "    for url in urls:\n",
    "        print(f\"*** task url_{i} create start\")\n",
    "        tasks.append(http_request(url))\n",
    "        print(f\"___ task url_{i} create end\")\n",
    "    # asyncio gather \n",
    "    print(\"### asyncio.gather\")  \n",
    "    result =  asyncio.gather(*tasks)\n",
    "    return result\n",
    "    \n",
    "print(await get_data())\n",
    "print(\"=\"*10)\n",
    "print(await get_data_no_await())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
